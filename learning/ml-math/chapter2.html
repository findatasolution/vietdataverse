<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 2: Distributions, Bayes & MLE - ML Mathematics</title>
  <link rel="stylesheet" href="../ml_book_shared-assets/styles.css">
  <link rel="stylesheet" href="../ml_book_shared-assets/custom-styles.css">
  <link rel="stylesheet" href="../ml_book_shared-assets/nav-styles.css">
  <link rel="stylesheet" href="../ml_book_shared-assets/chatgpt-styles.css">
  <link rel="stylesheet" href="../ml_book_shared-assets/responsive-fix.css">
</head>
<body>

<!-- Header -->
<div class="header">
  <h1>Machine Learning Mathematics</h1>

</div>

<!-- Sidebar Navigation -->
<div class="sidebar" id="sidebar">
  <!-- Will be populated by navigation.js -->
</div>

<!-- Toggle Sidebar Button (Mobile) -->
<button class="toggle-sidebar" id="toggleSidebar">☰ Menu</button>

<!-- Main Content -->
<div class="main-content">
  <div class="content-wrapper">

    <!-- Chapter Content -->
    <h1><span class="chapter-number">Chapter 2</span>Distributions, Bayes & MLE</h1>

    <h2>1. Why distributions matter in ML</h2>
<p>
Khi xây dựng mô hình ML, ta luôn ngầm giả định dữ liệu (hoặc noise của dữ liệu) tuân theo một phân phối nào đó.
Việc chọn phân phối đúng giúp mô hình học ổn định hơn và loss function có ý nghĩa thống kê rõ ràng.
</p>

<h2>2. Common Probability Distributions</h2>

<h3>2.1 Gaussian Distribution</h3>
<p>
Gaussian (Normal) distribution xuất hiện rất nhiều do Central Limit Theorem.
Trong Linear Regression, giả định phổ biến là noise ~ N(0, σ²).
</p>
<ul>
  <li>Mean (μ): giá trị trung tâm</li>
  <li>Variance (σ²): mức độ phân tán</li>
</ul>

<h3>2.2 Bernoulli Distribution</h3>
<p>
Bernoulli dùng cho biến nhị phân (0/1).
Logistic Regression giả định label tuân theo Bernoulli với tham số p.
</p>

<h3>2.3 Binomial Distribution</h3>
<p>
Binomial mô hình hóa số lần thành công trong N phép thử độc lập.
Thường dùng khi quan tâm đến tần suất xảy ra sự kiện.
</p>

<h3>2.4 Poisson Distribution</h3>
<p>
Poisson dùng cho dữ liệu dạng count (số lần xảy ra trong một khoảng thời gian).
Phù hợp cho event modeling hoặc rare events.
</p>

<h2>3. Conditional Probability</h2>
<p>
Conditional probability mô tả xác suất của Y khi biết X.
Trong ML, mục tiêu chính thường là ước lượng P(Y|X).
</p>

<h2>4. Bayes Theorem</h2>
<p>
Bayes Theorem cho phép biểu diễn:
</p>
<p>
P(Y|X) = P(X|Y)P(Y) / P(X)
</p>
<ul>
  <li>P(Y): Prior</li>
  <li>P(X|Y): Likelihood</li>
  <li>P(Y|X): Posterior</li>
</ul>

<h2>5. Naive Bayes (intuition)</h2>
<p>
Naive Bayes giả định các feature độc lập có điều kiện theo label.
Dù giả định này thường không đúng hoàn toàn, mô hình vẫn hoạt động tốt trong nhiều bài toán (đặc biệt là text).
</p>

<h2>6. Likelihood vs Probability</h2>
<p>
Probability: tham số cố định, dữ liệu là biến ngẫu nhiên.<br>
Likelihood: dữ liệu cố định, tham số là biến cần ước lượng.
</p>

<h2>7. Maximum Likelihood Estimation (MLE)</h2>
<p>
MLE tìm tham số sao cho likelihood của dữ liệu quan sát được là lớn nhất.
</p>

<h3>7.1 MLE và Linear Regression</h3>
<p>
Nếu giả định noise Gaussian, MLE dẫn đến việc tối thiểu hóa Mean Squared Error (MSE).
</p>

<h3>7.2 MLE và Logistic Regression</h3>
<p>
Với Bernoulli distribution, MLE dẫn đến Binary Cross-Entropy (Log-loss).
</p>

<h2>8. From Likelihood to Loss Function</h2>
<p>
Trong thực tế, ta thường tối thiểu hóa negative log-likelihood.
Đây chính là loss function trong hầu hết các model ML.
</p>

<h2>9. Typical Interview Questions</h2>
<ul>
  <li>Why MSE corresponds to Gaussian assumption?</li>
  <li>Why log-loss is used for classification?</li>
  <li>What does prior mean in Bayes?</li>
</ul>

<h2>10. Common Mistakes</h2>
<ul>
  <li>Chọn distribution không phù hợp với dữ liệu</li>
  <li>Nhầm lẫn likelihood và probability</li>
  <li>Không hiểu giả định đằng sau loss function</li>
</ul>

    <!-- Page Navigation -->
    <div class="page-navigation" id="pageNavigation">
      <!-- Will be populated by navigation.js -->
    </div>

  </div>
</div>

<script src="../ml_book_shared-assets/navigation.js"></script>
<script src="../ml_book_shared-assets/navigation-collapsible.js"></script>
<script src="../ml_book_shared-assets/math-config.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
<script src="../ml_book_shared-assets/navigation-collapsible.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    const collapsibles = document.querySelectorAll(".collapsible");
    collapsibles.forEach(header => {
      header.addEventListener("click", function() {
        const content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
        } else {
          content.style.display = "block";
        }
      });
    });
  });
</script>
</body>
</html>
